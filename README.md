# OpenAlex Data Pipeline & Citation Graph Builder

A modular toolkit for building domain/topic taxonomies, fetching papers from OpenAlex, analyzing professor/topic research, downloading OA PDFs, and constructing citation graphs with local LLM classification.

This repository contains:
- Taxonomy extraction from `data/field.txt`
- Paper collectors for professors and topics (OpenAlex API)
- Topic analysis for professors
- OA PDF downloader
- Citation graph builder that classifies citation types with a local Ollama model

## Contents
- data/
  - field.txt (input taxonomy table)
  - computer_science_entities.json, computer_science_relationships.json (generated by extract scripts)
  - cs_prof_list.json (professors mapping name -> OpenAlex author id)
  - domain-level/ (topic papers output)
  - output/computer_science/ (professor papers output)
- OpenAlex-Citation-Analyzer/
  - OpenAlex-Citation-Analyzer/parse_xml_openalex.py (TEI XML -> sentence_id.csv)
  - OpenAlex-Citation-Analyzer/citation_graph_pipeline.py (citation graph + LLM classification)
- analyze_professor_topics.py
- extract_hierarchy.py, extract_cs_hierarchy.py
- fetch_professor_papers.py, fetch_domain_papers.py, fetch_topic_papers.py
- download.py
- test_single_file.py

## Requirements
- Python 3.9+
- Internet access for OpenAlex API
- Optional: cloudscraper for better PDF download compatibility
- Optional: Ollama running locally for citation-type classification

Install Python dependencies:

```
pip install -r requirements.txt
```

## Data prerequisites
- `data/field.txt`: Tab-delimited taxonomy source with columns: topic_id, topic_name, subfield_id, subfield_name, field_id, field_name, domain_id, domain_name, keywords, summary, link.
- `data/cs_prof_list.json`: JSON mapping professor names to OpenAlex author IDs, e.g. `{ "Ada Lovelace": "A1234567890" }`.

## 1) Extract taxonomy entities and relationships
Scripts: `extract_hierarchy.py`, `extract_cs_hierarchy.py`

Purpose: Starting from a node name (domain/field/subfield), generate:
- Entities list with OpenAlex-compatible IDs (domain/field/subfield/topic)
- Parent-child relationships list

Output files (under data/):
- `<node>_entities.json`
- `<node>_relationships.json`

Usage example:

```
python extract_hierarchy.py "Computer Science"
```

Notes:
- Both `extract_hierarchy.py` and `extract_cs_hierarchy.py` implement the same logic.

## 2) Fetch papers for professors
Scripts: `fetch_professor_papers.py`, `fetch_domain_papers.py`

Purpose: For each professor (from `data/cs_prof_list.json`), fetch all works via OpenAlex, then for every work fetch:
- Citing works (filter `cited_by:<work_id>`)
- Cited works (filter `cites:<work_id>`)

Key functions:
- `fetch_papers_for_professor(author_id)` — paginates `/works?filter=author.id:...`
- `fetch_citing_works(work_id)` — uses `cited_by:<work_id>`
- `fetch_cited_works(work_id)` — uses `cites:<work_id>`

Output directory: `data/output/computer_science/`
- File name format: `<ProfessorName>_<AuthorID>_detail.json`
- Each paper is filtered to keep important fields: `id, doi, title, publication_date, open_access, primary_topic, abstract`, plus `cited_by_works` and `cited_works` (each filtered in the same way) and counts.

Run:

```
python fetch_professor_papers.py
```

`fetch_domain_papers.py` contains similar code structure; by default it also loads `data/cs_prof_list.json`.

## 3) Fetch papers for topics
Script: `fetch_topic_papers.py`

Purpose: For each topic entity in `data/computer_science_entities.json` (type == "topic"), fetch up to N works and their citation neighborhoods (bounded).

Highlights:
- Uses cursor pagination for large result sets
- Limits per-topic papers to avoid excessive API calls (default 200)

Output directory: `data/domain-level/`
- File name format: `<TopicName>_<TopicID>_papers.json`

Run:

```
python fetch_topic_papers.py
```

## 4) Analyze professor topics
Script: `analyze_professor_topics.py`

Purpose: Aggregate a professor’s papers (from their `_detail.json`) to summarize topics, and construct a compact taxonomy of entities (domain/field/subfield/topic) and relations relevant to the professor.

Inputs:
- A single professor file or a folder of `*_detail.json`
- Optional relationships file (e.g., `data/computer_science_relationships.json`) to enrich hierarchy relations

Default output folder: `professor_topics_output/`

Usage examples:

```
# Folder mode
python analyze_professor_topics.py data/output/computer_science data/computer_science_relationships.json professor_topics_output

# Single file mode
python analyze_professor_topics.py data/output/computer_science/Somebody_A123456_detail.json
```

## 5) Download OA PDFs
Script: `download.py`

Purpose: Traverse professor JSONs and download Open Access PDFs for:
- The professor’s main papers
- Their citing works per paper

Features:
- Optional cloudscraper session for tricky sites (ACM/IEEE/Springer/arXiv handling)
- File integrity checks (PDF signature, size threshold, HTML error-page detection)
- Saves as `<OpenAlexID>.pdf` into a flat download dir

Defaults:
- Reads JSONs from `output/computer_science` (note: top-level `output/`, not `data/output/`)
- Download dir: `/mnt/data/taxonomy/computer_science` (change via constructor or edit defaults)

Run:

```
python download.py
```

Tip: You can adapt `PaperDownloader(output_dir=..., download_dir=..., max_workers=...)` for your environment.

## 6) Build citation graphs with LLM-based citation typing
Location: `OpenAlex-Citation-Analyzer/OpenAlex-Citation-Analyzer/`

Two steps:

A) Extract citation sentences from TEI XML
- Script: `parse_xml_openalex.py`
- Scans TEI XML in `XML_DIR` and produces `sentence_id.csv` under `OUTPUT_DIR`
- Resolves `<ref target="...">` links; looks up OpenAlex works; includes fields like `original_work_id, sentence, ref_target, bib_*`

Key config (edit at top of file):
- `XML_DIR = "/mnt/data/taxonomy/xml"`
- `OUTPUT_DIR = Path("/mnt/data/yimian/xml_parse_output")`

Run:

```
python OpenAlex-Citation-Analyzer/OpenAlex-Citation-Analyzer/parse_xml_openalex.py
```

B) Build the citation graph and classify citation types
- Script: `citation_graph_pipeline.py`
- Inputs: an OpenAlex work ID (e.g., `W168389790`) and optional `sentence_id.csv`
- Fetches upstream (referenced_works) and downstream (citing works) via OpenAlex
- Calls local Ollama model to classify each edge into one of:
  `Method, Theory, Data, Application, Background, Comparison`

Ollama prerequisites:
- Install and run Ollama locally (default endpoint `http://localhost:11434`)
- Default model: `llama3:8b` (configurable via `--ollama-model`)
- Optional env var: `OLLAMA_API_URL` to override endpoint

Important: Evidence sentences are optional
- If no citation sentences are found, the classifier still works using titles/abstracts; the prompt shows `(no citation sentence available)`

Run:

```
python OpenAlex-Citation-Analyzer/OpenAlex-Citation-Analyzer/citation_graph_pipeline.py W168389790 \
  --sentence-csv OpenAlex-Citation-Analyzer/OpenAlex-Citation-Analyzer/sentence_id.csv \
  --output-dir OpenAlex-Citation-Analyzer/OpenAlex-Citation-Analyzer/outputs \
  --ollama-model llama3:8b \
  --max-upstream 50 \
  --max-downstream 100 \
  --verbose
```

Outputs:
- `outputs/citation_graph_<WID>.json` — nodes, edges, triples, entities grouped by upstream/downstream/neutral, expertise concepts, plus parameters and metadata
- `outputs/citation_graph_<WID>.log` — verbose progress log

## File/JSON schemas (high level)
- Professor file (`*_detail.json`):
  - `professor_info`: name, author_id, department, total_papers, fetch_date
  - `papers[]`: id, doi, title, publication_date, open_access, primary_topic, abstract, cited_by_works[], cited_works[], cited_by_count, cited_count
- Topic file (`*_papers.json`): `topic_info`, `papers[]` (same filtered fields as above)
- Citation graph output:
  - `triples[]`: subject, relation, object, type, direction, confidence, reason, evidence_sentences[], metadata
  - `graph.nodes[]`: id, title, publication_year, concepts[], roles
  - `graph.edges[]`: source, target, relation, type, direction, confidence
  - `entities`: upstream/downstream/neutral, plus `expertise_entities` aggregated by concept

## Rate limiting & reliability
- All API calls include small delays; adjust constants in scripts if needed
- Fetchers implement retries with exponential backoff
- Large paginations use `cursor` when supported

## Troubleshooting
- OpenAlex errors: Check network, retry; adjust `per_page` and delays
- Missing abstracts: `abstract_inverted_index` may be absent; scripts handle empty
- Ollama errors: ensure service up, model pulled, and `OLLAMA_API_URL` set if non-default
- TEI parsing: verify `XML_DIR` contains valid TEI with `<ref target="...">` links
- File paths: several scripts use absolute defaults; change to your environment

## Acknowledgements
- Data via OpenAlex API: https://openalex.org/
- Local LLM via Ollama: https://ollama.com/

## License
- The subproject under `OpenAlex-Citation-Analyzer/` includes its own LICENSE file. If you intend to distribute this repository, review and align licensing accordingly.
